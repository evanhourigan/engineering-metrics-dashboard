# Engineering Metrics Dashboard

A lightweight data platform and dashboard that ingests GitHub and Jira activity, computes DORA + flow metrics, and uses an LLM to surface **Sprint Health** insights and bottlenecksâ€”refreshing on a schedule and posting summaries to Slack.

<p align="center">
  <img src="docs/architecture.png" alt="Architecture Diagram" width="720"/>
</p>

## âœ¨ Highlights

- **End-to-end system**: ETL â†’ Warehouse â†’ API â†’ Web UI â†’ Slack.
- **DORA + Flow metrics**: Deployment frequency, lead time, PR cycle time, time-to-first-review, scope change %, carryover %.
- **AI Insights**: LLM-generated â€œSprint Healthâ€ card with risks and recommended actions.
- **Idempotent ETL**: Backfills and windowed incremental updates; rate-limit aware.
- **Batteries-included monorepo**: API (FastAPI), ETL jobs (Python), Dashboard (React), infra (Docker).

## ğŸ§­ Architecture Overview

**Sources**: GitHub + Jira â†’ **ETL Jobs** (Python, scheduled) â†’ **Warehouse** (Postgres or DuckDB) â†’ **API** (FastAPI) â†’ **Dashboard** (React) + **Slack Bot** for summaries.

Key design choices:

- **Materialized views** for expensive aggregations; refreshed per date window.
- **Stateless API** with clean filter semantics (org/team/repo/date).
- **LLM isolation**: small, deterministic prompt; retries with backoff; token caps.
- **Observability**: structured logs + simple request tracing and ETL run logs.

## ğŸ§± Monorepo Layout

```
engineering-metrics-dashboard/
â”œâ”€â”€ etl/                 # Ingestion jobs (GitHub/Jira) + schedulers
â”œâ”€â”€ api/                 # FastAPI service (metrics + insights endpoints)
â”œâ”€â”€ dashboard/           # React web app (tiles, charts, filters)
â”œâ”€â”€ db/                  # Schema, migrations, seeds, views
â”œâ”€â”€ infra/               # Docker, compose, deploy configs, Makefile
â”œâ”€â”€ tests/               # Unit + slim integration tests
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Data Model (v1)

Tables (simplified):

- `github_pull_requests(pr_id, repo, author, created_at, merged_at, first_review_at, reviewers[], comments_count, reopened_count, target_branch)`
- `github_commits(sha, pr_id, author, authored_at, committed_at)`
- `jira_issues(key, type, points, status, created_at, resolved_at, sprint_id, assignee)`
- `jira_sprints(id, name, start, end, completed)`
- `metrics_daily(org, team, repo, date, dora_*, flow_*, planning_*)` (denormalized cache)

Materialized views:

- `mv_dora_by_repo_day`
- `mv_flow_by_repo_day`
- `mv_planning_by_sprint`

## ğŸ“Š Core Metrics

- **DORA-ish**: Deployment Frequency (â‰ˆ merges to main), Lead Time for Changes (first commit â†’ merge).
- **Flow/Cycle**: PR cycle time (open â†’ merge), Time-to-First-Review, Review Depth, Rework Rate (re-opened PRs).
- **Planning/Predictability**: Planned vs. Done, Scope Change %, Carryover %, Blocked ticket age.
- **Quality proxy**: Hotfix rate (release-branch merges â‰¤ N days post release).

## ğŸ¤– Sprint Health (LLM)

**Inputs**: last sprint aggregates (cycle time p50/p90, review latency, scope change %, carryover %, deploy freq) + top anomalies.  
**Output** (â‰¤ 180 words): 3 insights, 2 risks, 3 recommendations (actionable and specific).

Prompt sketch:

```
Given the following sprint metrics and anomalies, summarize Sprint Health with:
- Three concise insights (what changed, by how much, why it matters)
- Two key risks (probable impact)
- Three specific recommendations
Keep it under 180 words.
DATA: {{json_metrics_blob}}
```

## ğŸ§ª API Surface (initial)

- `GET /metrics/tiles?team=&repo=&from=&to=` â†’ summary tiles.
- `GET /metrics/series/cycle-time?team=&repo=&granularity=day` â†’ timeseries.
- `GET /insights/sprint-health?team=&sprint=` â†’ current LLM card + source metrics.
- `POST /slack/summaries` â†’ web hook trigger (optional manual post).

## ğŸ” Config & Secrets

Environment variables (example):

```
GITHUB_TOKEN=...
JIRA_BASE_URL=https://your-domain.atlassian.net
JIRA_EMAIL=you@company.com
JIRA_API_TOKEN=...
DATABASE_URL=postgresql://metrics:metrics@db:5432/metrics
OPENAI_API_KEY=...
SLACK_BOT_TOKEN=xoxb-...
SLACK_CHANNEL_ID=C12345678
```

Use a secrets manager in production. Tokens should be least-privilege and revocable.

## ğŸš€ Running Locally

1. Install Docker & Docker Compose.
2. Clone repo and copy `env.example` â†’ `.env`, fill in tokens (or use mock mode).
3. Start services:
   ```bash
   docker compose up --build
   ```
4. Open:
   - API docs: http://localhost:8000/docs
   - Dashboard: http://localhost:5173

## ğŸ—“ï¸ Scheduling ETL

- Default: ETL jobs run hourly via APScheduler (inside ETL service) with backoff.
- First run does a **backfill** (last 30 days) to warm caches.

## ğŸ§¹ Quality & Observability

- **Tests**: `pytest` for ETL libs and API routes.
- **Lint/Type**: `ruff` + `mypy` (Python), `eslint` + `tsc` (frontend).
- **Logs**: JSON logs with run IDs; ETL success/failure counters.

## ğŸ›£ï¸ Roadmap

- OAuth setup flow + multi-tenant project config
- Team ownership mapping (CODEOWNERS â†’ repo/team)
- Anomaly detection (z-score) fed to insight prompts
- Drilldowns: PR type segmentation (feature/bug/hotfix)
- SLOs / error budgets view (service-level)
- Export to Notion/Google Slides for exec readouts

## ğŸ“¸ Demo Ideas

- 60â€“90s screencast: filter by team â†’ watch tiles update â†’ view Cycle Time p90 trend â†’ open Slackâ€™s end-of-sprint summary â†’ click back to dashboard.

## ğŸ“œ License

MIT (adjust as needed).
